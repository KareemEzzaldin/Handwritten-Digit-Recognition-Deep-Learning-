{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNEcHHcYU/as781pV0lhR67",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KareemEzzaldin/Handwritten-Digit-Recognition-Deep-Learning-/blob/main/Handwritten_Digit_Recognition_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hand Written"
      ],
      "metadata": {
        "id": "tTr0sFNlIaVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight"
      ],
      "metadata": {
        "id": "C8bjheysH6z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "-faRdkv-H9d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.drop('label', axis=1).values.astype(np.uint8)  # uint8 saves RAM\n",
        "y = train_df['label'].values.astype(np.int64)"
      ],
      "metadata": {
        "id": "WYcv3IA0ICU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "c2e9REFdIETI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))"
      ],
      "metadata": {
        "id": "11OCIceOIGeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = len(np.unique(y))\n",
        "\n",
        "def preprocess_image(features, label=None):\n",
        "    # Reshape to 28x28x1\n",
        "    image = tf.reshape(features, [28, 28, 1])\n",
        "    # Convert to RGB\n",
        "    image = tf.image.grayscale_to_rgb(image)\n",
        "    # Resize to 224x224\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    # Normalize to [0,1]\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    if label is None:\n",
        "        return image\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "LZ-hiPJdIIiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_ds = train_ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "val_ds = val_ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(test_df.values.astype(np.uint8))\n",
        "test_ds = test_ds.map(lambda x: preprocess_image(x, None), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.batch(1).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "5tG-SSOwILlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFnrIj_d0-eU",
        "outputId": "f36839ce-3b50-4b96-9c99-50205cf779fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m234698864/234698864\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
            "Epoch 1/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 550ms/step - accuracy: 0.1090 - loss: 2.6695 - val_accuracy: 0.1652 - val_loss: 2.2831 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 553ms/step - accuracy: 0.1426 - loss: 2.2886 - val_accuracy: 0.2942 - val_loss: 2.2190 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 554ms/step - accuracy: 0.1997 - loss: 2.1958 - val_accuracy: 0.4802 - val_loss: 1.9804 - learning_rate: 1.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 495ms/step - accuracy: 0.2605 - loss: 2.0539 - val_accuracy: 0.6196 - val_loss: 1.7162 - learning_rate: 1.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 557ms/step - accuracy: 0.3226 - loss: 1.8917 - val_accuracy: 0.6765 - val_loss: 1.5151 - learning_rate: 1.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 558ms/step - accuracy: 0.3771 - loss: 1.7533 - val_accuracy: 0.6720 - val_loss: 1.3715 - learning_rate: 1.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 558ms/step - accuracy: 0.4191 - loss: 1.6464 - val_accuracy: 0.6971 - val_loss: 1.2561 - learning_rate: 1.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 553ms/step - accuracy: 0.4527 - loss: 1.5511 - val_accuracy: 0.7220 - val_loss: 1.1577 - learning_rate: 1.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 498ms/step - accuracy: 0.4901 - loss: 1.4487 - val_accuracy: 0.7356 - val_loss: 1.0832 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 499ms/step - accuracy: 0.5200 - loss: 1.3796 - val_accuracy: 0.7582 - val_loss: 1.0038 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 558ms/step - accuracy: 0.5459 - loss: 1.3136 - val_accuracy: 0.7729 - val_loss: 0.9419 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 499ms/step - accuracy: 0.5675 - loss: 1.2591 - val_accuracy: 0.7887 - val_loss: 0.8951 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 495ms/step - accuracy: 0.5843 - loss: 1.2132 - val_accuracy: 0.8004 - val_loss: 0.8462 - learning_rate: 1.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 499ms/step - accuracy: 0.6050 - loss: 1.1636 - val_accuracy: 0.8082 - val_loss: 0.8093 - learning_rate: 1.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 495ms/step - accuracy: 0.6136 - loss: 1.1209 - val_accuracy: 0.8135 - val_loss: 0.7770 - learning_rate: 1.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 557ms/step - accuracy: 0.6286 - loss: 1.0929 - val_accuracy: 0.8265 - val_loss: 0.7349 - learning_rate: 1.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 556ms/step - accuracy: 0.6469 - loss: 1.0578 - val_accuracy: 0.8293 - val_loss: 0.7139 - learning_rate: 1.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 553ms/step - accuracy: 0.6623 - loss: 1.0167 - val_accuracy: 0.8361 - val_loss: 0.6882 - learning_rate: 1.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 552ms/step - accuracy: 0.6670 - loss: 0.9942 - val_accuracy: 0.8376 - val_loss: 0.6621 - learning_rate: 1.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 556ms/step - accuracy: 0.6726 - loss: 0.9718 - val_accuracy: 0.8427 - val_loss: 0.6410 - learning_rate: 1.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 494ms/step - accuracy: 0.6832 - loss: 0.9528 - val_accuracy: 0.8510 - val_loss: 0.6209 - learning_rate: 1.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 498ms/step - accuracy: 0.6886 - loss: 0.9372 - val_accuracy: 0.8537 - val_loss: 0.6050 - learning_rate: 1.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 556ms/step - accuracy: 0.6939 - loss: 0.9165 - val_accuracy: 0.8583 - val_loss: 0.5867 - learning_rate: 1.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 494ms/step - accuracy: 0.6987 - loss: 0.9026 - val_accuracy: 0.8615 - val_loss: 0.5705 - learning_rate: 1.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 557ms/step - accuracy: 0.7152 - loss: 0.8736 - val_accuracy: 0.8651 - val_loss: 0.5553 - learning_rate: 1.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 558ms/step - accuracy: 0.7153 - loss: 0.8622 - val_accuracy: 0.8677 - val_loss: 0.5413 - learning_rate: 1.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 494ms/step - accuracy: 0.7172 - loss: 0.8504 - val_accuracy: 0.8721 - val_loss: 0.5229 - learning_rate: 1.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 556ms/step - accuracy: 0.7218 - loss: 0.8374 - val_accuracy: 0.8736 - val_loss: 0.5177 - learning_rate: 1.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 553ms/step - accuracy: 0.7251 - loss: 0.8269 - val_accuracy: 0.8748 - val_loss: 0.5055 - learning_rate: 1.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 553ms/step - accuracy: 0.7322 - loss: 0.8119 - val_accuracy: 0.8781 - val_loss: 0.4937 - learning_rate: 1.0000e-04\n",
            "Epoch 1/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 616ms/step - accuracy: 0.7404 - loss: 2.7103 - val_accuracy: 0.9643 - val_loss: 0.1367 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 604ms/step - accuracy: 0.9244 - loss: 0.3248 - val_accuracy: 0.9743 - val_loss: 0.0886 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 549ms/step - accuracy: 0.9511 - loss: 0.1775 - val_accuracy: 0.9786 - val_loss: 0.0741 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 550ms/step - accuracy: 0.9597 - loss: 0.1323 - val_accuracy: 0.9787 - val_loss: 0.0697 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 549ms/step - accuracy: 0.9705 - loss: 0.0996 - val_accuracy: 0.9821 - val_loss: 0.0584 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 549ms/step - accuracy: 0.9746 - loss: 0.0801 - val_accuracy: 0.9826 - val_loss: 0.0605 - learning_rate: 1.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 549ms/step - accuracy: 0.9792 - loss: 0.0679 - val_accuracy: 0.9843 - val_loss: 0.0525 - learning_rate: 1.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 549ms/step - accuracy: 0.9820 - loss: 0.0561 - val_accuracy: 0.9838 - val_loss: 0.0553 - learning_rate: 1.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 549ms/step - accuracy: 0.9852 - loss: 0.0481 - val_accuracy: 0.9857 - val_loss: 0.0523 - learning_rate: 1.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m525/525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 607ms/step - accuracy: 0.9871 - loss: 0.0434 - val_accuracy: 0.9821 - val_loss: 0.0566 - learning_rate: 1.0000e-05\n",
            "\u001b[1m28000/28000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 22ms/step\n",
            "Saved submission.csv\n"
          ]
        }
      ],
      "source": [
        "base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.2, min_lr=1e-7)\n",
        "\n",
        "# Train (Feature Extraction)\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=30,\n",
        "    callbacks=[early_stopping, lr_reduction],\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "# Fine-tuning\n",
        "for layer in base_model.layers[-30:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "fine_tune_history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stopping, lr_reduction],\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "\n",
        "predictions = np.argmax(model.predict(test_ds), axis=1)\n",
        "\n",
        "submission = pd.DataFrame({'ImageId': np.arange(1, len(predictions) + 1), 'Label': predictions})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Saved submission.csv\")\n"
      ]
    }
  ]
}